import streamlit as st
import pandas as pd
import numpy as np
from numpy.ma.testutils import assert_array_almost_equal
from sklearn.svm import SVR
from sklearn.feature_selection import f_regression
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.model_selection import cross_val_score, KFold
import heapq
from collections import Counter
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.datasets import make_regression
from skopt import BayesSearchCV
from sklearn.cross_decomposition import PLSRegression
from scipy.optimize import minimize
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import r2_score, make_scorer
from io import BytesIO
file_out=BytesIO()#è®­ç»ƒæ•°æ®é¢„å¤„ç†åä¿å­˜åœ°å€
file_out_in=BytesIO()#é¢„æµ‹æ•°æ®é¢„å¤„ç†åä¿å­˜åœ°å€
kf1=25#ç‰¹å¾æŠ½ææ—¶SVRäº¤å‰éªŒè¯æŠ˜æ•°
kf2=2#æ¨¡å‹è®­ç»ƒæ—¶SVRäº¤å‰éªŒè¯æŠ˜æ•°
pls_a_n=5
pls_s_n=7
pre1='ä¸‹ä¸€äº§ç‰©'#é¢„æµ‹ç›®æ ‡
pre2='ä¸‹ä¸€åº•ç‰©'#é¢„æµ‹ç›®æ ‡
options_mpc_0=[]
@st.cache_data
def xd0():#æ·»åŠ å‘é…µæ—¶é—´
    excel_file = pd.ExcelFile(uploaded_file, engine="openpyxl")
    xls = pd.ExcelFile(excel_file)
    df = pd.read_excel(xls)
    columns = df.columns.tolist()
    n1 = len(columns)+1
    # åˆ›å»ºExcelWriterå¯¹è±¡ä»¥ä¿å­˜ç»“æœ
    with pd.ExcelWriter(file_out, engine='openpyxl') as writer:
        # éå†æ¯ä¸ªsheet
        for sheet_name in excel_file.sheet_names:
            df = pd.read_excel(excel_file, sheet_name=sheet_name, header=0, index_col=None)
            change_columns = {
                'å‘é…µæ—¶é—´': columns[0]
            }
            for new_col, base_col in change_columns.items():
                df[new_col] = df[base_col].diff()
            df.to_excel(writer, sheet_name=sheet_name, index=False)
    return n1

@st.cache_data
def xd1():#æ·»åŠ å˜åŒ–ç‰¹å¾
    xls = pd.ExcelFile(file_out)
    df = pd.read_excel(xls)
    # æ–°å»ºä¸€ä¸ªå­—å…¸å­˜å‚¨å¤„ç†åçš„æ¯ä¸ªsheet
    processed_sheets = {}
    # è·å–å½“å‰sheetçš„æ‰€æœ‰åˆ—å
    columns = df.columns.tolist()
    # éå†æ¯ä¸ªsheet
    for sheet_name in xls.sheet_names:
        # è¯»å–æ¯ä¸ªsheet
        df = xls.parse(sheet_name)
        columns_to_process = df.columns[1:n1 - 1]
        # è®¡ç®—å·®å€¼å¹¶æ·»åŠ åˆ°DataFrameä¸­
        for col in columns_to_process:
            df[f'{col}_å˜åŒ–'] = df[col].diff()
        # å°†å¤„ç†åçš„DataFrameå­˜å‚¨åœ¨å­—å…¸ä¸­
        processed_sheets[sheet_name] = df
    with pd.ExcelWriter(file_out) as writer:
        for sheet_name, df in processed_sheets.items():
            df.to_excel(writer, sheet_name=sheet_name, index=False)
    st.success("å·²æ‹“å±•â€œå˜åŒ–â€ç‰¹å¾")

@st.cache_data
def xd2():#æ·»åŠ å˜åŒ–ç‡ç‰¹å¾
    xls = pd.ExcelFile(file_out)
    df = pd.read_excel(xls)
    # æ–°å»ºä¸€ä¸ªå­—å…¸å­˜å‚¨å¤„ç†åçš„æ¯ä¸ªsheet
    processed_sheets = {}
    # è·å–å½“å‰sheetçš„æ‰€æœ‰åˆ—å
    columns = df.columns.tolist()
    n3 = len(columns)
    # éå†æ¯ä¸ªsheet
    for sheet_name in xls.sheet_names:
        # è¯»å–æ¯ä¸ªsheet
        df = xls.parse(sheet_name)
        for col in range(n1, n3):
            df[f'å˜åŒ–ç‡_{df.columns[col]}'] = df.iloc[:, col] / df['å‘é…µæ—¶é—´']
        processed_sheets[sheet_name] = df
    with pd.ExcelWriter(file_out) as writer:
        for sheet_name, df in processed_sheets.items():
            df.to_excel(writer, sheet_name=sheet_name, index=False)
    st.success("å·²æ‹“å±•â€œå˜åŒ–ç‡â€ç‰¹å¾")

@st.cache_data
def xd3():#æ·»åŠ æ—¶åºç‰¹å¾
    xls = pd.ExcelFile(file_out)
    df = pd.read_excel(xls)
    # æ–°å»ºä¸€ä¸ªå­—å…¸å­˜å‚¨å¤„ç†åçš„æ¯ä¸ªsheet
    processed_sheets = {}
    # è·å–å½“å‰sheetçš„æ‰€æœ‰åˆ—å
    columns = df.columns.tolist()
    n4 = len(columns)
    # éå†æ¯ä¸ªsheet
    for sheet_name in xls.sheet_names:
        # è¯»å–æ¯ä¸ªsheet
        df = xls.parse(sheet_name)
        for col in range(1, n4):
            # æ–°åˆ—çš„å€¼ä¸ºä¸Šä¸€è¡Œçš„æ•°æ®
            df[f'ä¸Šä¸€_{df.columns[col]}'] = df.iloc[:, col].shift(1)
        processed_sheets[sheet_name] = df
    with pd.ExcelWriter(file_out) as writer:
        for sheet_name, df in processed_sheets.items():
            df.to_excel(writer, sheet_name=sheet_name, index=False)
    st.success("å·²æ‹“å±•â€œæ—¶åºâ€ç‰¹å¾")

@st.cache_data
def xd4():#æ·»åŠ å¤šé¡¹å¼ç‰¹å¾
    xls = pd.ExcelFile(file_out)
    df = pd.read_excel(xls)
    # æ–°å»ºä¸€ä¸ªå­—å…¸å­˜å‚¨å¤„ç†åçš„æ¯ä¸ªsheet
    processed_sheets = {}
    # è·å–å½“å‰sheetçš„æ‰€æœ‰åˆ—å
    columns = df.columns.tolist()
    n5 = len(columns)
    # éå†æ¯ä¸ªsheet
    for sheet_name in xls.sheet_names:
        # è¯»å–æ¯ä¸ªsheet
        df = xls.parse(sheet_name)
        for col in range(1, n5):
            new_col_name = f"{df.columns[col]}_squared"  # æ–°ç‰¹å¾åˆ—åç§°
            df[new_col_name] = df.iloc[:, col] ** 2  # è®¡ç®—å¹³æ–¹å¹¶æ·»åŠ æ–°åˆ—
        processed_sheets[sheet_name] = df
    with pd.ExcelWriter(file_out) as writer:
        for sheet_name, df in processed_sheets.items():
            df.to_excel(writer, sheet_name=sheet_name, index=False)
    st.success("å·²æ‹“å±•â€œå¤šé¡¹å¼â€ç‰¹å¾")

@st.cache_data
def xd5():#æ·»åŠ ç´¯ç§¯ç‰¹å¾
    xls = pd.ExcelFile(file_out)
    df = pd.read_excel(xls)
    # æ–°å»ºä¸€ä¸ªå­—å…¸å­˜å‚¨å¤„ç†åçš„æ¯ä¸ªsheet
    processed_sheets = {}
    # è·å–å½“å‰sheetçš„æ‰€æœ‰åˆ—å
    columns = df.columns.tolist()
    n6 = len(columns)
    # éå†æ¯ä¸ªsheet
    for sheet_name in xls.sheet_names:
        # è¯»å–æ¯ä¸ªsheet
        df = xls.parse(sheet_name)
        if f'{df.columns[1]}_å˜åŒ–' in df.columns:
            df['è€—ç³–ç´¯ç§¯é‡'] = df[f'{df.columns[1]}_å˜åŒ–'].cumsum()
        if 'ç¢±é‡kg_å˜åŒ–' in df.columns:
            df['è€—ç¢±ç´¯ç§¯é‡'] = df['ç¢±é‡kg_å˜åŒ–'].cumsum()
        processed_sheets[sheet_name] = df
    with pd.ExcelWriter(file_out) as writer:
        for sheet_name, df in processed_sheets.items():
            df.to_excel(writer, sheet_name=sheet_name, index=False)
    st.success("å·²æ‹“å±•â€œç´¯ç§¯â€ç‰¹å¾")

@st.cache_data
def xd6():#æ·»åŠ è½¬åŒ–ç‡ç‰¹å¾
    xls = pd.ExcelFile(file_out)
    df = pd.read_excel(xls)
    # æ–°å»ºä¸€ä¸ªå­—å…¸å­˜å‚¨å¤„ç†åçš„æ¯ä¸ªsheet
    processed_sheets = {}
    # è·å–å½“å‰sheetçš„æ‰€æœ‰åˆ—å
    columns = df.columns.tolist()
    n7 = len(columns)
    # éå†æ¯ä¸ªsheet
    for sheet_name in xls.sheet_names:
        # è¯»å–æ¯ä¸ªsheet
        df = xls.parse(sheet_name)
        if f'{df.columns[2]}_å˜åŒ–' in df.columns and f'{df.columns[1]}_å˜åŒ–' in df.columns:
            df['äº§ç‰©è½¬åŒ–ç‡'] = df[f'{df.columns[2]}_å˜åŒ–']/ df[f'{df.columns[1]}_å˜åŒ–']
        if 'èŒæµ“g/50mL_å˜åŒ–' in df.columns and f'{df.columns[1]}_å˜åŒ–' in df.columns:
            df['èŒä½“gè½¬åŒ–ç‡'] = df['èŒæµ“g/50mL_å˜åŒ–'] / df[f'{df.columns[1]}_å˜åŒ–']
        if 'èŒæµ“mL/50mL_å˜åŒ–' in df.columns and f'{df.columns[1]}_å˜åŒ–' in df.columns:
            df['èŒä½“mLè½¬åŒ–ç‡'] = df['èŒæµ“mL/50mL_å˜åŒ–'] / df[f'{df.columns[1]}_å˜åŒ–']
        processed_sheets[sheet_name] = df
    with pd.ExcelWriter(file_out) as writer:
        for sheet_name, df in processed_sheets.items():
            df.to_excel(writer, sheet_name=sheet_name, index=False)

@st.cache_data
def xd7():#æ·»åŠ ç”Ÿç‰©å­¦ç‰¹å¾
    xls = pd.ExcelFile(file_out)
    df = pd.read_excel(xls)
    # æ–°å»ºä¸€ä¸ªå­—å…¸å­˜å‚¨å¤„ç†åçš„æ¯ä¸ªsheet
    processed_sheets = {}
    # è·å–å½“å‰sheetçš„æ‰€æœ‰åˆ—å
    columns = df.columns.tolist()
    n8 = len(columns)
    # éå†æ¯ä¸ªsheet
    for sheet_name in xls.sheet_names:
        # è¯»å–æ¯ä¸ªsheet
        df = xls.parse(sheet_name)
        if 'èŒæµ“mL/50mL' in df.columns and 'å‘é…µæ—¶é—´' in df.columns:
            df['æ¯”ç”Ÿé•¿é€Ÿç‡ml'] = np.log(df['èŒæµ“mL/50mL'] / df['èŒæµ“mL/50mL'].shift(1)) / df['å‘é…µæ—¶é—´']
        if 'èŒæµ“g/50mL' in df.columns and 'å‘é…µæ—¶é—´' in df.columns:
            df['æ¯”ç”Ÿé•¿é€Ÿç‡g'] = np.log(df['èŒæµ“g/50mL'] / df['èŒæµ“g/50mL'].shift(1)) / df['å‘é…µæ—¶é—´']
        processed_sheets[sheet_name] = df
    with pd.ExcelWriter(file_out) as writer:
        for sheet_name, df in processed_sheets.items():
            df.to_excel(writer, sheet_name=sheet_name, index=False)
    st.success("å·²æ‹“å±•â€œç”Ÿç‰©å­¦â€ç‰¹å¾")

@st.cache_data
def xd8():#æ·»åŠ é¢„æµ‹ç›®æ ‡
    xls = pd.ExcelFile(file_out)
    df = pd.read_excel(xls)
    # æ–°å»ºä¸€ä¸ªå­—å…¸å­˜å‚¨å¤„ç†åçš„æ¯ä¸ªsheet
    processed_sheets = {}
    # è·å–å½“å‰sheetçš„æ‰€æœ‰åˆ—å
    columns = df.columns.tolist()
    n9 = len(columns)
    # éå†æ¯ä¸ªsheet
    for sheet_name in xls.sheet_names:
        # è¯»å–æ¯ä¸ªsheet
        df = xls.parse(sheet_name)
        df['ä¸‹ä¸€äº§ç‰©'] = df[f'{df.columns[2]}'].shift(-1)
        df['ä¸‹ä¸€åº•ç‰©'] = df[f'{df.columns[1]}'].shift(-1)
        processed_sheets[sheet_name] = df
    with pd.ExcelWriter(file_out) as writer:
        for sheet_name, df in processed_sheets.items():
            df.to_excel(writer, sheet_name=sheet_name, index=False)

@st.cache_data
def xd9():#å¤šä¸ªsheetåˆå¹¶
    def merge_sheets(input_file, output_file):
        try:
            # 1. è¯»å–Excelæ–‡ä»¶
            xls = pd.ExcelFile(input_file)
            # 2. åˆå§‹åŒ–å­˜å‚¨åˆå¹¶æ•°æ®çš„åˆ—è¡¨
            all_data = []
            # 3. éå†æ‰€æœ‰sheet
            for sheet_name in xls.sheet_names:
                # è¯»å–å½“å‰sheetæ•°æ®ï¼ˆç¬¬ä¸€è¡Œä¸ºåˆ—åï¼Œä»ç¬¬äºŒè¡Œå¼€å§‹ä¸ºæ•°æ®ï¼‰
                df = pd.read_excel(xls, sheet_name=sheet_name, header=0)
                # æ·»åŠ åˆ°åˆå¹¶åˆ—è¡¨
                all_data.append(df)
            # 4. åˆå¹¶æ‰€æœ‰æ•°æ®
            merged_data = pd.concat(all_data, ignore_index=True)
            # 5. ä¿å­˜ç»“æœ
            merged_data.to_excel(output_file, index=False)
            st.success("ç‰¹å¾æ‹“å±•å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼šd3")
        except FileNotFoundError:
            st.error(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ {input_file}")
        except Exception as e:
            st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
    if __name__ == "__main__":
        input_path = file_out  # è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_path = file_out  # è¾“å‡ºæ–‡ä»¶è·¯å¾„
        merge_sheets(input_path, output_path)

@st.cache_data
def fscore1_a(pre):#äº§ç‰©é¢„æµ‹ï¼šè®¡ç®—f-scoreå€¼
    # è¯»å–Excelæ–‡ä»¶
    df = pd.read_excel(uploaded_file_1, engine='openpyxl')
    df = df[~df.isna().any(axis=1)]
    # æå–ç›®æ ‡å˜é‡y
    y = df[pre]
    # æå–ç‰¹å¾Xï¼ˆä»ç¬¬ä¸€åˆ—åˆ°å€’æ•°ç¬¬ä¸‰åˆ—ï¼‰
    X = df.iloc[:, :-2]
    # æ ‡å‡†åŒ–ç‰¹å¾X
    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(X)

    # ä½¿ç”¨SVRè¿›è¡Œè®­ç»ƒ
    svr = SVR(kernel='linear')  # ä½¿ç”¨çº¿æ€§æ ¸çš„SVR
    svr.fit(X_scaled, y)

    # è·å–SVRæ¨¡å‹ä¸­çš„ç‰¹å¾ç³»æ•°ï¼Œè¿™äº›ç³»æ•°å¯ä»¥è§†ä½œF-score
    feature_importance = svr.coef_[0]  # è·å–ç‰¹å¾ç³»æ•°

    # å¯¹ç‰¹å¾è¿›è¡Œæ’å
    feature_ranking = sorted(zip(X.columns, feature_importance), key=lambda x: abs(x[1]), reverse=True)

    # ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨f_regressionæ¥è®¡ç®—F-score
    f_scores, _ = f_regression(X_scaled, y)

    # è¾“å‡ºé€šè¿‡f_regressionè®¡ç®—çš„F-scoresæ’å
    f_score_ranking = sorted(zip(X.columns, f_scores), key=lambda x: x[1], reverse=True)
    return f_score_ranking

@st.cache_data
def fscore_a(pre,lis1):#äº§ç‰©é¢„æµ‹ï¼šäºŒåˆ†æ³•ç‰¹å¾æŠ½æ
    lis = [item[0] for item in lis1]
    # è¯»å–Excelæ–‡ä»¶ä¸­çš„æ‰€æœ‰sheet
    file_path = uploaded_file_1
    data = pd.read_excel(file_path)  # è¯»å–
    data = data.dropna(how='any')#åˆ é™¤åŒ…å«ç©ºå€¼æ ·æœ¬ç‚¹
    #æœ€é«˜åˆ†æ•°ç‰¹å¾
    feature = lis
    features = feature[:1]
    target = pre
    # åˆ†å‰²æ•°æ®é›†
    X = data[features]
    y = data[target]

    X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.2)

    X_train = X_train.to_numpy()
    X_test = X_test.to_numpy()
    y_train = y_train.to_numpy()
    y_test = y_test.to_numpy()
    # åˆå§‹åŒ–æ ‡å‡†åŒ–å™¨
    scaler_X = MinMaxScaler()
    scaler_y= MinMaxScaler()

    # å¯¹è®­ç»ƒé›†è¿›è¡Œæ‹Ÿåˆå’Œå˜æ¢
    X_train = scaler_X.fit_transform(X_train)
    y_train = scaler_y.fit_transform(y_train.reshape(-1, 1)).reshape(-1)

    # å¯¹æµ‹è¯•é›†ä»…è¿›è¡Œå˜æ¢
    X_test = scaler_X.transform(X_test)
    y_test = scaler_y.transform(y_test.reshape(-1, 1)).reshape(-1)

    X1 = X_train
    y1 = y_train

    # åˆ›å»ºSVRæ¨¡å‹ï¼Œä½¿ç”¨çº¿æ€§æ ¸å‡½æ•°
    regressor = SVR(kernel='linear',C=1,epsilon=0.01)
    kf = KFold(n_splits=kf1, shuffle=True)#äº¤å‰éªŒè¯æŠ˜æ•°
    scores = cross_val_score(regressor, X1, y1, cv=kf, scoring='neg_mean_squared_error')

    # è®¡ç®—å¹³å‡ MSE
    average_mse_1 = np.mean(-scores)

    #å…¨éƒ¨ç‰¹å¾
    feature = lis
    features = feature[:len(lis)]
    target = pre

    # åˆ†å‰²æ•°æ®é›†
    X = data[features]
    y = data[target]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

    X_train = X_train.to_numpy()
    X_test = X_test.to_numpy()
    y_train = y_train.to_numpy()
    y_test = y_test.to_numpy()
    # åˆå§‹åŒ–æ ‡å‡†åŒ–å™¨
    scaler_X = MinMaxScaler()
    scaler_y = MinMaxScaler()

    # å¯¹è®­ç»ƒé›†è¿›è¡Œæ‹Ÿåˆå’Œå˜æ¢
    X_train = scaler_X.fit_transform(X_train)
    y_train = scaler_y.fit_transform(y_train.reshape(-1, 1)).reshape(-1)

    # å¯¹æµ‹è¯•é›†ä»…è¿›è¡Œå˜æ¢
    X_test = scaler_X.transform(X_test)
    y_test = scaler_y.transform(y_test.reshape(-1, 1)).reshape(-1)

    X1 = X_train
    y1 = y_train

    # åˆ›å»ºSVRæ¨¡å‹ï¼Œä½¿ç”¨RBFæ ¸å‡½æ•°
    regressor = SVR(kernel='linear',C=1,epsilon=0.01)
    kf = KFold(n_splits=kf1, shuffle=True)# äº¤å‰éªŒè¯
    scores = cross_val_score(regressor, X1, y1, cv=kf, scoring='neg_mean_squared_error')

    # è®¡ç®—å¹³å‡ MSE
    average_mse_all = np.mean(-scores)
    ev = 1
    mse_ev = average_mse_1
    EV = len(lis)
    mse_EV = average_mse_all

    def find_greater_than_m(data, m):#å¯»æ‰¾dataåˆ—è¡¨ä¸­å¤§äºmçš„å…ƒç´ 
        # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼æ‰¾åˆ°æ‰€æœ‰å¤§äºmçš„å…ƒç´ 
        result = [x for x in data if x > m]
        return result

    #lis1(åç§°ï¼Œåˆ†æ•°) lis(åç§°) lis2(åˆ†æ•°)
    lis2 = [item[1] for item in lis1]
    while abs(EV - ev) > 1:
        med = lis2[int((EV + ev)/2)]#EVä¸evä¸­å€¼
        new_list = find_greater_than_m(lis2, med)#å¤§äºä¸­å€¼çš„ç‰¹å¾
        n = len(new_list)

        feature = lis
        features = feature[:n]
        target = pre
        # åˆ†å‰²æ•°æ®é›†
        X = data[features]
        y = data[target]

        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

        X_train = X_train.to_numpy()
        X_test = X_test.to_numpy()
        y_train = y_train.to_numpy()
        y_test = y_test.to_numpy()
        # åˆå§‹åŒ–æ ‡å‡†åŒ–å™¨
        scaler_X = MinMaxScaler()
        scaler_y = MinMaxScaler()

        # å¯¹è®­ç»ƒé›†è¿›è¡Œæ‹Ÿåˆå’Œå˜æ¢
        X_train = scaler_X.fit_transform(X_train)
        y_train = scaler_y.fit_transform(y_train.reshape(-1, 1)).reshape(-1)

        # å¯¹æµ‹è¯•é›†ä»…è¿›è¡Œå˜æ¢
        X_test = scaler_X.transform(X_test)
        y_test = scaler_y.transform(y_test.reshape(-1, 1)).reshape(-1)

        X1 = X_train
        y1 = y_train

        # åˆ›å»ºSVRæ¨¡å‹ï¼Œä½¿ç”¨çº¿æ€§æ ¸å‡½æ•°
        regressor = SVR(kernel='linear',C=1,epsilon=0.01)
        kf = KFold(n_splits=kf1, shuffle=True)
        scores = cross_val_score(regressor, X1, y1, cv=kf, scoring='neg_mean_squared_error')

        # è®¡ç®—å¹³å‡ MSE
        average_mse = np.mean(-scores)

        if average_mse <= mse_EV:
            mse_EV = average_mse
            EV = n
        else:
            mse_ev = average_mse
            ev = n
    return EV

@st.cache_data
def fscore1_s(pre):#åº•ç‰©é¢„æµ‹ï¼šè®¡ç®—f-scoreå€¼
    # è¯»å–Excelæ–‡ä»¶
    df = pd.read_excel(uploaded_file_1, engine='openpyxl')
    df = df[~df.isna().any(axis=1)]
    # æå–ç›®æ ‡å˜é‡y
    y = df[pre]
    # æå–ç‰¹å¾Xï¼ˆä»ç¬¬ä¸€åˆ—åˆ°å€’æ•°ç¬¬ä¸‰åˆ—ï¼‰
    X = df.iloc[:, :-2]

    # æ ‡å‡†åŒ–ç‰¹å¾X
    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(X)

    # ä½¿ç”¨SVRè¿›è¡Œè®­ç»ƒ
    svr = SVR(kernel='linear')  # ä½¿ç”¨çº¿æ€§æ ¸çš„SVR
    svr.fit(X_scaled, y)

    # è·å–SVRæ¨¡å‹ä¸­çš„ç‰¹å¾ç³»æ•°ï¼Œè¿™äº›ç³»æ•°å¯ä»¥è§†ä½œF-score
    feature_importance = svr.coef_[0]  # è·å–ç‰¹å¾ç³»æ•°

    # å¯¹ç‰¹å¾è¿›è¡Œæ’å
    feature_ranking = sorted(zip(X.columns, feature_importance), key=lambda x: abs(x[1]), reverse=True)

    # ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨f_regressionæ¥è®¡ç®—F-score
    f_scores, _ = f_regression(X_scaled, y)

    # è¾“å‡ºé€šè¿‡f_regressionè®¡ç®—çš„F-scoresæ’å
    f_score_ranking = sorted(zip(X.columns, f_scores), key=lambda x: x[1], reverse=True)
    return f_score_ranking

@st.cache_data
def fscore_s(pre,lis1):#åº•ç‰©é¢„æµ‹ï¼šäºŒåˆ†æ³•ç‰¹å¾æŠ½æ
    lis = [item[0] for item in lis1]
    # è¯»å–Excelæ–‡ä»¶ä¸­çš„æ‰€æœ‰sheet
    file_path = uploaded_file_1
    data = pd.read_excel(file_path)  # è¯»å–
    data = data.dropna(how='any')#åˆ é™¤åŒ…å«ç©ºå€¼çš„æ ·æœ¬ç‚¹
    # æœ€é«˜åˆ†æ•°ç‰¹å¾
    feature = lis
    features = feature[:1]
    target = pre
    # åˆ†å‰²æ•°æ®é›†
    X = data[features]
    y = data[target]

    X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.2)

    X_train = X_train.to_numpy()
    X_test = X_test.to_numpy()
    y_train = y_train.to_numpy()
    y_test = y_test.to_numpy()
    # åˆå§‹åŒ–æ ‡å‡†åŒ–å™¨
    scaler_X = MinMaxScaler()
    scaler_y= MinMaxScaler()
    # å¯¹è®­ç»ƒé›†è¿›è¡Œæ‹Ÿåˆå’Œå˜æ¢
    X_train = scaler_X.fit_transform(X_train)
    y_train = scaler_y.fit_transform(y_train.reshape(-1, 1)).reshape(-1)
    # å¯¹æµ‹è¯•é›†ä»…è¿›è¡Œå˜æ¢
    X_test = scaler_X.transform(X_test)
    y_test = scaler_y.transform(y_test.reshape(-1, 1)).reshape(-1)

    X1 = X_train
    y1 = y_train

    # åˆ›å»ºSVRæ¨¡å‹ï¼Œä½¿ç”¨çº¿æ€§æ ¸å‡½æ•°
    regressor = SVR(kernel='linear',C=1,epsilon=0.01)
    kf = KFold(n_splits=kf1, shuffle=True)
    scores = cross_val_score(regressor, X1, y1, cv=kf, scoring='neg_mean_squared_error')

    # è®¡ç®—å¹³å‡ MSE
    average_mse_1 = np.mean(-scores)

    # å…¨éƒ¨ç‰¹å¾
    feature = lis
    features = feature[:len(lis)]
    target = pre

    # åˆ†å‰²æ•°æ®é›†
    X = data[features]
    y = data[target]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

    X_train = X_train.to_numpy()
    X_test = X_test.to_numpy()
    y_train = y_train.to_numpy()
    y_test = y_test.to_numpy()
            # åˆå§‹åŒ–æ ‡å‡†åŒ–å™¨
    scaler_X = MinMaxScaler()
    scaler_y = MinMaxScaler()

    # å¯¹è®­ç»ƒé›†è¿›è¡Œæ‹Ÿåˆå’Œå˜æ¢
    X_train = scaler_X.fit_transform(X_train)
    y_train = scaler_y.fit_transform(y_train.reshape(-1, 1)).reshape(-1)

    # å¯¹æµ‹è¯•é›†ä»…è¿›è¡Œå˜æ¢
    X_test = scaler_X.transform(X_test)
    y_test = scaler_y.transform(y_test.reshape(-1, 1)).reshape(-1)

    X1 = X_train
    y1 = y_train

    # åˆ›å»ºSVRæ¨¡å‹ï¼Œä½¿ç”¨çº¿æ€§æ ¸å‡½æ•°
    regressor = SVR(kernel='linear',C=1,epsilon=0.01)
    kf = KFold(n_splits=kf1, shuffle=True)
    scores = cross_val_score(regressor, X1, y1, cv=kf, scoring='neg_mean_squared_error')

    # è®¡ç®—å¹³å‡ MSE
    average_mse_all = np.mean(-scores)
    ev = 1
    mse_ev = average_mse_1
    EV = len(lis)
    mse_EV = average_mse_all

    def find_greater_than_m(data, m):#æ‰¾å‡ºdataåˆ—è¡¨ä¸­å¤§äºmçš„å…ƒç´ 
        # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼æ‰¾åˆ°æ‰€æœ‰å¤§äºmçš„å…ƒç´ 
        result = [x for x in data if x > m]
        return result

    #lis1(åç§°ï¼Œåˆ†æ•°) lis(åç§°) lis2(åˆ†æ•°)
    lis2 = [item[1] for item in lis1]
    while abs(EV - ev) > 1:
        med = lis2[int((EV+ev)/2)]#EVä¸evé—´ä¸­å€¼
        new_list = find_greater_than_m(lis2, med)#æ‰¾å‡ºæ‰€æœ‰å¤§äºä¸­å€¼çš„ç‰¹å¾
        n = len(new_list)

        feature = lis
        features = feature[:n]
        target = pre

        # åˆ†å‰²æ•°æ®é›†
        X = data[features]
        y = data[target]

        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

        X_train = X_train.to_numpy()
        X_test = X_test.to_numpy()
        y_train = y_train.to_numpy()
        y_test = y_test.to_numpy()
        # åˆå§‹åŒ–æ ‡å‡†åŒ–å™¨
        scaler_X = MinMaxScaler()
        scaler_y = MinMaxScaler()

        # å¯¹è®­ç»ƒé›†è¿›è¡Œæ‹Ÿåˆå’Œå˜æ¢
        X_train = scaler_X.fit_transform(X_train)
        y_train = scaler_y.fit_transform(y_train.reshape(-1, 1)).reshape(-1)

        # å¯¹æµ‹è¯•é›†ä»…è¿›è¡Œå˜æ¢
        X_test = scaler_X.transform(X_test)
        y_test = scaler_y.transform(y_test.reshape(-1, 1)).reshape(-1)

        X1 = X_train
        y1 = y_train

        # åˆ›å»ºSVRæ¨¡å‹ï¼Œä½¿ç”¨RBFæ ¸å‡½æ•°
        regressor = SVR(kernel='linear',C=1,epsilon=0.01)
        kf = KFold(n_splits=kf1, shuffle=True)
        scores = cross_val_score(regressor, X1, y1, cv=kf, scoring='neg_mean_squared_error')

        # è®¡ç®—å¹³å‡ MSE
        average_mse = np.mean(-scores)

        if average_mse <= mse_EV:
            mse_EV = average_mse
            EV = n
        else:
            mse_ev = average_mse
            ev = n
    return EV

@st.cache_data
def svrm_a(pre,lis):#åº•ç‰©é¢„æµ‹SVRæ¨¡å‹
    data = pd.read_excel(uploaded_file_1, engine='openpyxl')  # è¯»å–
    data = data.dropna(how='any')#åˆ é™¤åŒ…å«ç©ºå€¼çš„æ ·æœ¬ç‚¹
    # SVR
    features = lis
    target = pre

    # åˆ†å‰²æ•°æ®é›†
    X = data[features]
    y = data[target]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

    X_train = X_train.to_numpy()
    X_test = X_test.to_numpy()
    y_train = y_train.to_numpy()
    y_test = y_test.to_numpy()
    # åˆå§‹åŒ–æ ‡å‡†åŒ–å™¨
    scaler_X = MinMaxScaler()
    scaler_y = MinMaxScaler()

    # å¯¹è®­ç»ƒé›†è¿›è¡Œæ‹Ÿåˆå’Œå˜æ¢
    X_train = scaler_X.fit_transform(X_train)
    y_train = scaler_y.fit_transform(y_train.reshape(-1, 1)).reshape(-1)

    # å¯¹æµ‹è¯•é›†ä»…è¿›è¡Œå˜æ¢
    X_test = scaler_X.transform(X_test)
    y_test = scaler_y.transform(y_test.reshape(-1, 1)).reshape(-1)

    X1 = X_train
    y1 = y_train
    #å°è£…è¯„åˆ†å™¨
    r2_scorer = make_scorer(r2_score, greater_is_better=True)
    # å®šä¹‰SVRæ¨¡å‹çš„è¶…å‚æ•°æœç´¢ç©ºé—´
    search_space = {
                'C': (1e-2, 1e+2, 'log-uniform'),  # æƒ©ç½šé¡¹å‚æ•° C
                'epsilon': (0.01,1),  # æŸå¤±å‡½æ•°çš„ epsilon
                'kernel': ['linear', 'rbf'],  # æ ¸å‡½æ•°ç±»å‹
                'gamma': ['scale', 'auto'],  # gamma
            }

    # ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–è¿›è¡Œè¶…å‚æ•°æœç´¢
    opt = BayesSearchCV(
                SVR(),  # æ¨¡å‹
                search_space,  # è¶…å‚æ•°ç©ºé—´
                n_iter=25,  # è¿­ä»£æ¬¡æ•°
                cv=5,  # äº¤å‰éªŒè¯æ¬¡æ•°
                scoring=r2_scorer#è¯„åˆ†æ ‡å‡†
            )

    # æ‹Ÿåˆæ¨¡å‹
    opt.fit(X1, y1)

    # åˆ›å»ºSVRæ¨¡å‹
    regressor_svr_a = SVR(C=opt.best_params_['C'], epsilon=opt.best_params_['epsilon'],
                                gamma=opt.best_params_['gamma'], kernel=opt.best_params_['kernel'])

    #mseã€maeã€r2æŒ‡æ ‡
    scores = cross_val_score(regressor_svr_a, X1, y1, cv=kf2, scoring='neg_mean_squared_error')
    scores_mae = cross_val_score(regressor_svr_a, X1, y1, cv=kf2, scoring='neg_mean_absolute_error')
    scores_r2 = cross_val_score(regressor_svr_a, X1, y1, cv=kf2, scoring='r2')
    # è®¡ç®—å¹³å‡å€¼
    mse = np.mean(-scores)
    rmse = np.sqrt(mse)
    mae = np.mean(-scores_mae)
    r2 = np.mean(scores_r2)
    # è¾“å‡ºç»“æœ
    st.markdown("SVRæ¨¡å‹æ€§èƒ½æŒ‡æ ‡ï¼š")
    st.markdown(f"MSE: {mse}")
    st.markdown(f"RMSE: {rmse}")
    st.markdown(f"MAE: {mae}")
    st.markdown(f"RÂ²: {r2}")
    regressor_svr_a.fit(X1, y1)#è®­ç»ƒæ¨¡å‹
    return regressor_svr_a,mse,scaler_X,scaler_y

@st.cache_data
def svrm_s(pre,lis):#åº•ç‰©é¢„æµ‹SVRæ¨¡å‹
    data = pd.read_excel(uploaded_file_1, engine='openpyxl')
    data = data.dropna(how='any')#åˆ é™¤åŒ…å«ç©ºå€¼çš„æ ·æœ¬ç‚¹
    # SVR
    features = lis
    target = pre

    # åˆ†å‰²æ•°æ®é›†
    X = data[features]
    y = data[target]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

    X_train = X_train.to_numpy()
    X_test = X_test.to_numpy()
    y_train = y_train.to_numpy()
    y_test = y_test.to_numpy()
    # åˆå§‹åŒ–æ ‡å‡†åŒ–å™¨
    scaler_X = MinMaxScaler()
    scaler_y = MinMaxScaler()

    # å¯¹è®­ç»ƒé›†è¿›è¡Œæ‹Ÿåˆå’Œå˜æ¢
    X_train = scaler_X.fit_transform(X_train)
    y_train = scaler_y.fit_transform(y_train.reshape(-1, 1)).reshape(-1)

    # å¯¹æµ‹è¯•é›†ä»…è¿›è¡Œå˜æ¢
    X_test = scaler_X.transform(X_test)
    y_test = scaler_y.transform(y_test.reshape(-1, 1)).reshape(-1)

    X1 = X_train
    y1 = y_train
    r2_scorer = make_scorer(r2_score, greater_is_better=True)#å°è£…è¯„åˆ†å™¨
    # å®šä¹‰SVRæ¨¡å‹çš„è¶…å‚æ•°æœç´¢ç©ºé—´
    search_space = {
                'C': (1e-2, 1e+2, 'log-uniform'),  # æƒ©ç½šé¡¹å‚æ•° C
                'epsilon': (0.01,1),  # æŸå¤±å‡½æ•°çš„ epsilon
                'kernel': ['linear', 'rbf'],  # æ ¸å‡½æ•°ç±»å‹
                'gamma': ['scale', 'auto'],  # gamma
            }

    # ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–è¿›è¡Œè¶…å‚æ•°æœç´¢
    opt = BayesSearchCV(
                SVR(),  # æ¨¡å‹
                search_space,  # è¶…å‚æ•°ç©ºé—´
                n_iter=25,  # è¿­ä»£æ¬¡æ•°
                cv=5,  # äº¤å‰éªŒè¯æ¬¡æ•°
                scoring=r2_scorer#è¯„åˆ†æ ‡å‡†
            )

    # æ‹Ÿåˆæ¨¡å‹
    opt.fit(X1, y1)

    # åˆ›å»ºSVRæ¨¡å‹
    regressor_svr_s = SVR(C=opt.best_params_['C'], epsilon=opt.best_params_['epsilon'],
                                gamma=opt.best_params_['gamma'], kernel=opt.best_params_['kernel'])

    #mseã€maeã€r2æŒ‡æ ‡
    scores = cross_val_score(regressor_svr_s, X1, y1, cv=kf2, scoring='neg_mean_squared_error')
    scores_mae = cross_val_score(regressor_svr_s, X1, y1, cv=kf2, scoring='neg_mean_absolute_error')
    scores_r2 = cross_val_score(regressor_svr_s, X1, y1, cv=kf2, scoring='r2')
    # è®¡ç®—å¹³å‡å€¼
    mse = np.mean(-scores)
    rmse = np.sqrt(mse)
    mae = np.mean(-scores_mae)
    r2 = np.mean(scores_r2)
    # è¾“å‡ºç»“æœ
    st.markdown("SVRæ¨¡å‹æ€§èƒ½æŒ‡æ ‡ï¼š")
    st.markdown(f"MSE: {mse}")
    st.markdown(f"RMSE: {rmse}")
    st.markdown(f"MAE: {mae}")
    st.markdown(f"RÂ²: {r2}")
    regressor_svr_s.fit(X1,y1)#è®­ç»ƒæ¨¡å‹
    return regressor_svr_s,mse,scaler_X,scaler_y

@st.cache_data
def plssvrm_a(pre,lis):#äº§ç‰©é¢„æµ‹PLS-SVRæ¨¡å‹
    data = pd.read_excel(uploaded_file_1, engine='openpyxl')
    data = data.dropna(how='any')#åˆ é™¤åŒ…å«ç©ºå€¼çš„æ ·æœ¬ç‚¹
    # SVR
    features = lis
    target = pre

    # åˆ†å‰²æ•°æ®é›†
    X = data[features]
    y = data[target]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

    X_train = X_train.to_numpy()
    X_test = X_test.to_numpy()
    y_train = y_train.to_numpy()
    y_test = y_test.to_numpy()
    # åˆå§‹åŒ–æ ‡å‡†åŒ–å™¨
    scaler_X = MinMaxScaler()
    scaler_y = MinMaxScaler()

    # å¯¹è®­ç»ƒé›†è¿›è¡Œæ‹Ÿåˆå’Œå˜æ¢
    X_train = scaler_X.fit_transform(X_train)
    y_train = scaler_y.fit_transform(y_train.reshape(-1, 1)).reshape(-1)

    # å¯¹æµ‹è¯•é›†ä»…è¿›è¡Œå˜æ¢
    X_test = scaler_X.transform(X_test)
    y_test = scaler_y.transform(y_test.reshape(-1, 1)).reshape(-1)

    # ä½¿ç”¨ PLS è¿›è¡Œç‰¹å¾æå–ï¼Œé€‰æ‹©æå–5ä¸ªä¸»æˆåˆ†
    pls = PLSRegression(n_components=pls_a_n)

    # æ‹Ÿåˆ PLS æ¨¡å‹
    pls.fit(X_train, y_train)

    # æå–ç‰¹å¾ï¼Œå¾—åˆ°æ–°çš„ç‰¹å¾çŸ©é˜µ X_plsï¼ˆç»è¿‡é™ç»´åçš„æ•°æ®ï¼‰
    X_pls = pls.transform(X_train)
    X_test_pls = pls.transform(X_test)

    X1 = X_pls
    y1 = y_train
    r2_scorer = make_scorer(r2_score, greater_is_better=True)#å°è£…è¯„åˆ†å™¨
    # å®šä¹‰SVRæ¨¡å‹çš„è¶…å‚æ•°æœç´¢ç©ºé—´
    search_space = {
                'C': (1e-2, 1e+2, 'log-uniform'),  # æƒ©ç½šé¡¹å‚æ•° C
                'epsilon': (0.01,1),  # æŸå¤±å‡½æ•°çš„ epsilon
                'kernel': ['linear', 'rbf'],  # æ ¸å‡½æ•°ç±»å‹
                'gamma': ['scale', 'auto'],  # gamma
            }

    # ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–è¿›è¡Œè¶…å‚æ•°æœç´¢
    opt = BayesSearchCV(
                SVR(),  # æ¨¡å‹
                search_space,  # è¶…å‚æ•°ç©ºé—´
                n_iter=25,  # è¿­ä»£æ¬¡æ•°
                cv=5,  # äº¤å‰éªŒè¯æ¬¡æ•°
                scoring=r2_scorer#è¯„åˆ†æ ‡å‡†
            )

    # æ‹Ÿåˆæ¨¡å‹
    opt.fit(X1, y1)

    # åˆ›å»ºSVRæ¨¡å‹
    regressor_plssvr_a = SVR(C=opt.best_params_['C'], epsilon=opt.best_params_['epsilon'],
                                gamma=opt.best_params_['gamma'], kernel=opt.best_params_['kernel'])
    #mseã€maeã€r2æŒ‡æ ‡
    scores = cross_val_score(regressor_plssvr_a, X1, y1, cv=kf2, scoring='neg_mean_squared_error')
    scores_mae = cross_val_score(regressor_plssvr_a, X1, y1, cv=kf2, scoring='neg_mean_absolute_error')
    scores_r2 = cross_val_score(regressor_plssvr_a, X1, y1, cv=kf2, scoring='r2')
    # è®¡ç®—å¹³å‡å€¼
    mse = np.mean(-scores)
    rmse = np.sqrt(mse)
    mae = np.mean(-scores_mae)
    r2 = np.mean(scores_r2)
    # è¾“å‡ºç»“æœ
    st.markdown("PLS-SVRæ¨¡å‹æ€§èƒ½æŒ‡æ ‡ï¼š")
    st.markdown(f"MSE: {mse}")
    st.markdown(f"RMSE: {rmse}")
    st.markdown(f"MAE: {mae}")
    st.markdown(f"RÂ²: {r2}")
    regressor_plssvr_a.fit(X1, y1)#è®­ç»ƒæ¨¡å‹
    return regressor_plssvr_a,mse,scaler_X,scaler_y,pls.transform

@st.cache_data
def plssvrm_s(pre,lis):#åº•ç‰©é¢„æµ‹PLS-SVRæ¨¡å‹
    data = pd.read_excel(uploaded_file_1, engine='openpyxl')
    data = data.dropna(how='any')#åˆ é™¤åŒ…å«ç©ºå€¼çš„æ ·æœ¬ç‚¹
    # SVR
    features = lis
    target = pre

    # åˆ†å‰²æ•°æ®é›†
    X = data[features]
    y = data[target]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

    X_train = X_train.to_numpy()
    X_test = X_test.to_numpy()
    y_train = y_train.to_numpy()
    y_test = y_test.to_numpy()
    # åˆå§‹åŒ–æ ‡å‡†åŒ–å™¨
    scaler_X = MinMaxScaler()
    scaler_y = MinMaxScaler()

    # å¯¹è®­ç»ƒé›†è¿›è¡Œæ‹Ÿåˆå’Œå˜æ¢
    X_train = scaler_X.fit_transform(X_train)
    y_train = scaler_y.fit_transform(y_train.reshape(-1, 1)).reshape(-1)

    # å¯¹æµ‹è¯•é›†ä»…è¿›è¡Œå˜æ¢
    X_test = scaler_X.transform(X_test)
    y_test = scaler_y.transform(y_test.reshape(-1, 1)).reshape(-1)

    # ä½¿ç”¨ PLS è¿›è¡Œç‰¹å¾æå–ï¼Œé€‰æ‹©æå–7ä¸ªä¸»æˆåˆ†
    pls = PLSRegression(n_components=pls_s_n)

    # æ‹Ÿåˆ PLS æ¨¡å‹
    pls.fit(X_train, y_train)

    # æå–ç‰¹å¾ï¼Œå¾—åˆ°æ–°çš„ç‰¹å¾çŸ©é˜µ X_plsï¼ˆç»è¿‡é™ç»´åçš„æ•°æ®ï¼‰
    X_pls = pls.transform(X_train)
    X_test_pls = pls.transform(X_test)

    X1 = X_pls
    y1 = y_train
    r2_scorer = make_scorer(r2_score, greater_is_better=True)#å°è£…è¯„åˆ†å™¨
    # å®šä¹‰SVRæ¨¡å‹çš„è¶…å‚æ•°æœç´¢ç©ºé—´
    search_space = {
                'C': (1e-2, 1e+2, 'log-uniform'),  # æƒ©ç½šé¡¹å‚æ•° C
                'epsilon': (0.01,1),  # æŸå¤±å‡½æ•°çš„ epsilon
                'kernel': ['linear', 'rbf'],  # æ ¸å‡½æ•°ç±»å‹
                'gamma': ['scale', 'auto'],  #gamma
            }

            # ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–è¿›è¡Œè¶…å‚æ•°æœç´¢
    opt = BayesSearchCV(
                SVR(),  # æ¨¡å‹
                search_space,  # è¶…å‚æ•°ç©ºé—´
                n_iter=25,  # è¿­ä»£æ¬¡æ•°
                cv=5,  # äº¤å‰éªŒè¯æ¬¡æ•°
                scoring=r2_scorer#è¯„åˆ†æ ‡å‡†
            )

    # æ‹Ÿåˆæ¨¡å‹
    opt.fit(X1, y1)

    # åˆ›å»ºSVRæ¨¡å‹ï¼Œä½¿ç”¨RBFæ ¸å‡½æ•°
    regressor_plssvr_s = SVR(C=opt.best_params_['C'], epsilon=opt.best_params_['epsilon'],
                                gamma=opt.best_params_['gamma'], kernel=opt.best_params_['kernel'])
    # mseã€maeã€r2æŒ‡æ ‡
    scores = cross_val_score(regressor_plssvr_s, X1, y1, cv=kf2, scoring='neg_mean_squared_error')
    scores_mae = cross_val_score(regressor_plssvr_s, X1, y1, cv=kf2, scoring='neg_mean_absolute_error')
    scores_r2 = cross_val_score(regressor_plssvr_s, X1, y1, cv=kf2, scoring='r2')
    # è®¡ç®—å¹³å‡å€¼
    mse = np.mean(-scores)
    rmse = np.sqrt(mse)
    mae = np.mean(-scores_mae)
    r2 = np.mean(scores_r2)
    # è¾“å‡ºç»“æœ
    st.markdown("PLS-SVRæ¨¡å‹æ€§èƒ½æŒ‡æ ‡ï¼š")
    st.markdown(f"MSE: {mse}")
    st.markdown(f"RMSE: {rmse}")
    st.markdown(f"MAE: {mae}")
    st.markdown(f"RÂ²: {r2}")
    regressor_plssvr_s.fit(X1, y1)#è®­ç»ƒæ¨¡å‹
    return regressor_plssvr_s,mse,scaler_X,scaler_y,pls.transform


#é¢„æµ‹
@st.cache_data
def xd00():#æ·»åŠ å‘é…µæ—¶é—´
    excel_file = pd.ExcelFile(uploaded_file1, engine="openpyxl")
    xls = pd.ExcelFile(excel_file)
    df = pd.read_excel(xls)
    columns = df.columns.tolist()
    m1 = len(columns)+1
    # åˆ›å»ºExcelWriterå¯¹è±¡ä»¥ä¿å­˜ç»“æœ
    with pd.ExcelWriter(file_out_in) as writer:
        # éå†æ¯ä¸ªsheet
        for sheet_name in excel_file.sheet_names:
            df = pd.read_excel(excel_file, sheet_name=sheet_name, header=0, index_col=None)
            change_columns = {
                'å‘é…µæ—¶é—´': columns[0]
            }
            for new_col, base_col in change_columns.items():
                df[new_col] = df[base_col].diff()
            df.to_excel(writer, sheet_name=sheet_name, index=False)
    return m1

@st.cache_data
def xd11():#æ·»åŠ å˜åŒ–ç‰¹å¾
    xls = pd.ExcelFile(file_out_in)
    df = pd.read_excel(xls)
    # æ–°å»ºä¸€ä¸ªå­—å…¸å­˜å‚¨å¤„ç†åçš„æ¯ä¸ªsheet
    processed_sheets = {}
    # è·å–å½“å‰sheetçš„æ‰€æœ‰åˆ—å
    columns = df.columns.tolist()
    # éå†æ¯ä¸ªsheet
    for sheet_name in xls.sheet_names:
        # è¯»å–æ¯ä¸ªsheet
        df = xls.parse(sheet_name)
        columns_to_process = df.columns[1:m1 - 1]
        # è®¡ç®—å·®å€¼å¹¶æ·»åŠ åˆ°DataFrameä¸­
        for col in columns_to_process:
            df[f'{col}_å˜åŒ–'] = df[col].diff()
        # å°†å¤„ç†åçš„DataFrameå­˜å‚¨åœ¨å­—å…¸ä¸­
        processed_sheets[sheet_name] = df
    with pd.ExcelWriter(file_out_in) as writer:
        for sheet_name, df in processed_sheets.items():
            df.to_excel(writer, sheet_name=sheet_name, index=False)

@st.cache_data
def xd22():#æ·»åŠ å˜åŒ–ç‰¹å¾
    xls = pd.ExcelFile(file_out_in)
    df = pd.read_excel(xls)
    # æ–°å»ºä¸€ä¸ªå­—å…¸å­˜å‚¨å¤„ç†åçš„æ¯ä¸ªsheet
    processed_sheets = {}
    # è·å–å½“å‰sheetçš„æ‰€æœ‰åˆ—å
    columns = df.columns.tolist()
    n3 = len(columns)
    # éå†æ¯ä¸ªsheet
    for sheet_name in xls.sheet_names:
        # è¯»å–æ¯ä¸ªsheet
        df = xls.parse(sheet_name)
        for col in range(m1, n3):
            df[f'å˜åŒ–ç‡_{df.columns[col]}'] = df.iloc[:, col] / df['å‘é…µæ—¶é—´']
        processed_sheets[sheet_name] = df
    with pd.ExcelWriter(file_out_in) as writer:
        for sheet_name, df in processed_sheets.items():
            df.to_excel(writer, sheet_name=sheet_name, index=False)

@st.cache_data
def xd33():#æ·»åŠ å˜åŒ–ç‡ç‰¹å¾
    xls = pd.ExcelFile(file_out_in)
    df = pd.read_excel(xls)
    # æ–°å»ºä¸€ä¸ªå­—å…¸å­˜å‚¨å¤„ç†åçš„æ¯ä¸ªsheet
    processed_sheets = {}
    # è·å–å½“å‰sheetçš„æ‰€æœ‰åˆ—å
    columns = df.columns.tolist()
    n4 = len(columns)
    # éå†æ¯ä¸ªsheet
    for sheet_name in xls.sheet_names:
        # è¯»å–æ¯ä¸ªsheet
        df = xls.parse(sheet_name)
        for col in range(1, n4):
            # æ–°åˆ—çš„å€¼ä¸ºä¸Šä¸€è¡Œçš„æ•°æ®
            df[f'ä¸Šä¸€_{df.columns[col]}'] = df.iloc[:, col].shift(1)
        processed_sheets[sheet_name] = df
    with pd.ExcelWriter(file_out_in) as writer:
        for sheet_name, df in processed_sheets.items():
            df.to_excel(writer, sheet_name=sheet_name, index=False)

@st.cache_data
def xd44():#æ·»åŠ å¤šé¡¹å¼ç‰¹å¾
    xls = pd.ExcelFile(file_out_in)
    df = pd.read_excel(xls)
    # æ–°å»ºä¸€ä¸ªå­—å…¸å­˜å‚¨å¤„ç†åçš„æ¯ä¸ªsheet
    processed_sheets = {}
    # è·å–å½“å‰sheetçš„æ‰€æœ‰åˆ—å
    columns = df.columns.tolist()
    n5 = len(columns)
    # éå†æ¯ä¸ªsheet
    for sheet_name in xls.sheet_names:
        # è¯»å–æ¯ä¸ªsheet
        df = xls.parse(sheet_name)
        for col in range(1, n5):
            new_col_name = f"{df.columns[col]}_squared"  # æ–°ç‰¹å¾åˆ—åç§°
            df[new_col_name] = df.iloc[:, col] ** 2  # è®¡ç®—å¹³æ–¹å¹¶æ·»åŠ æ–°åˆ—
        processed_sheets[sheet_name] = df
    with pd.ExcelWriter(file_out_in) as writer:
        for sheet_name, df in processed_sheets.items():
            df.to_excel(writer, sheet_name=sheet_name, index=False)

@st.cache_data
def xd55():#æ·»åŠ ç´¯ç§¯ç‰¹å¾
    xls = pd.ExcelFile(file_out_in)
    df = pd.read_excel(xls)
    # æ–°å»ºä¸€ä¸ªå­—å…¸å­˜å‚¨å¤„ç†åçš„æ¯ä¸ªsheet
    processed_sheets = {}
    # è·å–å½“å‰sheetçš„æ‰€æœ‰åˆ—å
    columns = df.columns.tolist()
    n6 = len(columns)
    # éå†æ¯ä¸ªsheet
    for sheet_name in xls.sheet_names:
        # è¯»å–æ¯ä¸ªsheet
        df = xls.parse(sheet_name)
        if f'{df.columns[1]}_å˜åŒ–' in df.columns:
            df['è€—ç³–ç´¯ç§¯é‡'] = df[f'{df.columns[1]}_å˜åŒ–'].cumsum()
        if 'ç¢±é‡kg_å˜åŒ–' in df.columns:
            df['è€—ç¢±ç´¯ç§¯é‡'] = df['ç¢±é‡kg_å˜åŒ–'].cumsum()
        processed_sheets[sheet_name] = df
    with pd.ExcelWriter(file_out_in) as writer:
        for sheet_name, df in processed_sheets.items():
            df.to_excel(writer, sheet_name=sheet_name, index=False)

@st.cache_data
def xd66():#æ·»åŠ è½¬åŒ–ç‡ç‰¹å¾
    xls = pd.ExcelFile(file_out_in)
    df = pd.read_excel(xls)
    # æ–°å»ºä¸€ä¸ªå­—å…¸å­˜å‚¨å¤„ç†åçš„æ¯ä¸ªsheet
    processed_sheets = {}
    # è·å–å½“å‰sheetçš„æ‰€æœ‰åˆ—å
    columns = df.columns.tolist()
    n7 = len(columns)
    # éå†æ¯ä¸ªsheet
    for sheet_name in xls.sheet_names:
        # è¯»å–æ¯ä¸ªsheet
        df = xls.parse(sheet_name)
        if f'{df.columns[2]}_å˜åŒ–' in df.columns and f'{df.columns[1]}_å˜åŒ–' in df.columns:
            df['äº§ç‰©è½¬åŒ–ç‡'] = df[f'{df.columns[2]}_å˜åŒ–']/ df[f'{df.columns[1]}_å˜åŒ–']
        if 'èŒæµ“g/50mL_å˜åŒ–' in df.columns and f'{df.columns[1]}_å˜åŒ–' in df.columns:
            df['èŒä½“gè½¬åŒ–ç‡'] = df['èŒæµ“g/50mL_å˜åŒ–'] / df[f'{df.columns[1]}_å˜åŒ–']
        if 'èŒæµ“mL/50mL_å˜åŒ–' in df.columns and f'{df.columns[1]}_å˜åŒ–' in df.columns:
            df['èŒä½“mLè½¬åŒ–ç‡'] = df['èŒæµ“mL/50mL_å˜åŒ–'] / df[f'{df.columns[1]}_å˜åŒ–']

        processed_sheets[sheet_name] = df
    with pd.ExcelWriter(file_out_in) as writer:
        for sheet_name, df in processed_sheets.items():
            df.to_excel(writer, sheet_name=sheet_name, index=False)

@st.cache_data
def xd77():#æ·»åŠ ç”Ÿç‰©å­¦ç‰¹å¾
    xls = pd.ExcelFile(file_out_in)
    df = pd.read_excel(xls)
    # æ–°å»ºä¸€ä¸ªå­—å…¸å­˜å‚¨å¤„ç†åçš„æ¯ä¸ªsheet
    processed_sheets = {}
    # è·å–å½“å‰sheetçš„æ‰€æœ‰åˆ—å
    columns = df.columns.tolist()
    n8 = len(columns)
    # éå†æ¯ä¸ªsheet
    for sheet_name in xls.sheet_names:
        # è¯»å–æ¯ä¸ªsheet
        df = xls.parse(sheet_name)
        if 'èŒæµ“mL/50mL' in df.columns and 'å‘é…µæ—¶é—´' in df.columns:
            df['æ¯”ç”Ÿé•¿é€Ÿç‡ml'] = np.log(df['èŒæµ“mL/50mL'] / df['èŒæµ“mL/50mL'].shift(1)) / df['å‘é…µæ—¶é—´']
        if 'èŒæµ“g/50mL' in df.columns and 'å‘é…µæ—¶é—´' in df.columns:
            df['æ¯”ç”Ÿé•¿é€Ÿç‡g'] = np.log(df['èŒæµ“g/50mL'] / df['èŒæµ“g/50mL'].shift(1)) / df['å‘é…µæ—¶é—´']
        processed_sheets[sheet_name] = df
    with pd.ExcelWriter(file_out_in) as writer:
        for sheet_name, df in processed_sheets.items():
            df.to_excel(writer, sheet_name=sheet_name, index=False)

@st.cache_data
def xd88():
    excel_file2 = pd.ExcelFile(file_out_in, engine="openpyxl")
    xls2 = pd.ExcelFile(excel_file2)
    df22 = pd.read_excel(xls2)
    prdata = df22.iloc[-1]  # æå–æœ€åä¸€è¡Œï¼ˆå¾…é¢„æµ‹æ•°æ®ï¼‰
    st.write(prdata)
    return df22,prdata

st.title("åŸºäºSVRçš„ç”Ÿç‰©è¿‡ç¨‹é¢„æµ‹")
# åˆ›å»ºä¸€ä¸ªæŒ‰é’®
if st.button('è¯´æ˜ä¹¦'):
    with st.expander("åŸºäºSVRçš„ç”Ÿç‰©è¿‡ç¨‹é¢„æµ‹ä½¿ç”¨è¯´æ˜ä¹¦"):
        st.markdown("1. ç³»ç»Ÿæ¦‚è¿°")
        st.markdown("è¯¥ç½‘ç«™ä¸»è¦åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼šç”Ÿç‰©è¿‡ç¨‹é¢„æµ‹ï¼Œæ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆå¯é€‰ï¼‰")
        st.markdown("2. ç”Ÿç‰©è¿‡ç¨‹é¢„æµ‹")
        st.markdown("ç”Ÿç‰©è¿‡ç¨‹é¢„æµ‹åŒ…å«5ä¸ªæ¨¡å—")
        st.markdown("2.1 æ–‡ä»¶è¯»å–")
        st.markdown("åŠŸèƒ½ï¼šè¯»å–é€‰æ‹©çš„åŒ…å«è®­ç»ƒæ•°æ®çš„Excelæ–‡ä»¶ã€‚")
        st.markdown("æ³¨æ„ï¼šæ–‡ä»¶åº”åŒ…å«å¤šä¸ªsheetï¼ˆæ¯ä¸ªsheetè¡¨ç¤ºä¸€ä¸ªæ‰¹æ¬¡ï¼‰ï¼Œæ¯ä¸ªsheetçš„æ ¼å¼å¦‚ä¸‹ï¼šæ¨ªè½´ä¸ºæµ‹é‡ç‚¹ï¼Œçºµè½´ä¸ºç‰¹å¾åç§°ï¼Œç‰¹å¾åç§°é¡ºåºä¸ºï¼šå‘é…µå‘¨æœŸ/hã€åº•ç‰©ã€äº§ç‰©ã€å…¶ä»–ç‰¹å¾1ã€å…¶ä»–ç‰¹å¾2...ï¼ˆå‰ä¸‰ä¸ªç‰¹å¾ä¸å¯æ”¹å˜ï¼ŒèŒæµ“ç›¸å…³ç‰¹å¾åº”å‘½åä¸ºâ€œèŒæµ“mL/50mLâ€æˆ–â€œèŒæµ“g/50mLâ€ï¼‰ã€‚æµ‹é‡æ—¶é—´é—´éš”åº”å°½å¯èƒ½ç›¸ç­‰ã€‚")
        st.markdown("æ“ä½œï¼šç‚¹å‡»â€œæ–‡ä»¶è¯»å–â€æŒ‰é’®ä»¥è¯»å–è®­ç»ƒæ•°æ®ï¼Œéšåå¯ç‚¹å‡»â€œæ–‡ä»¶é¢„è§ˆâ€æŒ‰é’®ä»¥æµè§ˆè¯»å–çš„è®­ç»ƒæ•°æ®ã€‚åœ¨å¤šé€‰æ¡†ä¸­é€‰æ‹©æ“ä½œå‚æ•°")
        st.markdown("2.2 ç‰¹å¾æ‹“å±•")
        st.markdown("åŠŸèƒ½ï¼šå¯¹å·²æœ‰çš„ç‰¹å¾è¿›è¡Œæ‹“å±•ï¼Œä¸°å¯Œæ•°æ®ç‰¹å¾ï¼Œæ›´å¥½çš„å­¦ä¹ å…¶ä¸­çš„è§„å¾‹")
        st.markdown("å»ºè®®ï¼šå»ºè®®å…¨é€‰æ‰€æœ‰ç‰¹å¾è¿›è¡Œæ‹“å±•ã€‚")
        st.markdown("æ“ä½œï¼šå¤šé€‰æ¡†é€‰æ‹©æ‹“å±•ç±»å‹ï¼Œç‚¹å‡»â€œå¼€å§‹æ‹“å±•â€æŒ‰é’®è¿›è¡Œç‰¹å¾æ‹“å±•ï¼Œæ‹“å±•å®Œæˆåï¼Œæ•°æ®å°†ä¿å­˜ä¸ºåä¸ºâ€œd3â€çš„Excelæ–‡ä»¶ã€‚ç‚¹å‡»â€œå¤„ç†æ•°æ®é¢„è§ˆâ€æŒ‰é’®ä»¥é¢„è§ˆæ‹“å±•åçš„æ•°æ®ã€‚")
        st.markdown("2.3 ç‰¹å¾æŠ½æ")
        st.markdown("åŠŸèƒ½ï¼šå¯¹äº§ç‰©é¢„æµ‹æ¨¡å‹ä¸åº•ç‰©é¢„æµ‹æ¨¡å‹è¿›è¡Œç‰¹å¾æŠ½æã€‚")
        st.markdown("æ“ä½œï¼šç‚¹å‡»â€œå¼€å§‹ç‰¹å¾æŠ½æâ€æŒ‰é’®ï¼Œç³»ç»Ÿå°†å¼€å§‹ç‰¹å¾æŠ½æè¿‡ç¨‹ã€‚å®Œæˆåï¼Œä¼šå±•ç¤ºäº§ç‰©é¢„æµ‹æ¨¡å‹ä¸åº•ç‰©é¢„æµ‹æ¨¡å‹æ‰€æŠ½æçš„ç‰¹å¾ã€‚")
        st.markdown("æç¤ºï¼šæ­¤è¿‡ç¨‹å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚")
        st.markdown("2.4 æ¨¡å‹è®­ç»ƒ")
        st.markdown("åŠŸèƒ½ï¼šè®­ç»ƒä¸åŒç±»å‹çš„SVRæ¨¡å‹ï¼ŒåŒ…æ‹¬äº§ç‰©é¢„æµ‹æ¨¡å‹ä¸åº•ç‰©é¢„æµ‹æ¨¡å‹ã€‚")
        st.markdown("æ“ä½œï¼šç‚¹å‡»â€œå¼€å§‹è®­ç»ƒäº§ç‰©é¢„æµ‹æ¨¡å‹â€ä¸â€œå¼€å§‹è®­ç»ƒåº•ç‰©é¢„æµ‹æ¨¡å‹â€æŒ‰é’®ï¼Œç³»ç»Ÿå°†åˆ†åˆ«è®­ç»ƒä¸åŒæ¨¡å‹ã€‚è®­ç»ƒå®Œæˆåï¼Œç³»ç»Ÿå°†å±•ç¤ºå„ä¸ªæ¨¡å‹çš„æ€§èƒ½æŒ‡æ ‡ã€‚")
        st.markdown("æç¤ºï¼šæ­¤è¿‡ç¨‹å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚MSEã€RMSEã€MAEè¶Šä½ï¼ŒRæ–¹è¶Šé«˜ï¼Œæ¨¡å‹æ€§èƒ½è¶Šå¥½ã€‚")
        st.markdown("2.5 é¢„æµ‹")
        st.markdown("åŠŸèƒ½ï¼šé¢„æµ‹å¾…æµ‹æ•°æ®çš„äº§ç‰©ç”Ÿæˆé€Ÿç‡ä¸ä¸‹ä¸€ä¸ªæµ‹é‡ç‚¹çš„äº§ç‰©æµ“åº¦ã€‚")
        st.markdown("æ“ä½œï¼š")
        st.markdown("â‘ ä¸Šä¼ å¾…é¢„æµ‹çš„æ•°æ®ã€‚ç¡®ä¿æ•°æ®çš„ç‰¹å¾åˆ—ä¸è®­ç»ƒæ•°æ®å®Œå…¨ç›¸åŒï¼Œä¸”è‡³å°‘åŒ…å«ä¸‰ä¸ªæµ‹é‡ç‚¹ã€‚")
        st.markdown("â‘¡è¾“å…¥å‘é…µå‘¨æœŸ")
        st.markdown("â‘¢ç‚¹å‡»â€œè¾“å…¥æ•°æ®é¢„å¤„ç†â€æŒ‰é’®ï¼Œæ•°æ®å°†æ ¹æ®â€œç‰¹å¾æ‹“å±•â€ä¸­çš„è®¾ç½®è¿›è¡Œç›¸åŒç±»å‹çš„æ‹“å±•ã€‚")
        st.markdown("â‘£é¢„å¤„ç†å®Œæˆåï¼Œå±•ç¤ºå¤„ç†åçš„å¾…é¢„æµ‹æ•°æ®ã€‚")
        st.markdown("â‘¤é€‰æ‹©â€œå¼€å§‹é¢„æµ‹äº§ç‰©â€æˆ–â€œå¼€å§‹é¢„æµ‹åº•ç‰©â€æŒ‰é’®è¿›è¡Œé¢„æµ‹ã€‚é€‰æ‹©ä¸€ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼ˆæ¨èé€‰æ‹©MSEè¾ƒä½çš„æ¨¡å‹ï¼‰ã€‚")
        st.markdown("3. æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆå¯é€‰ï¼‰")
        st.markdown("æ“ä½œï¼š")
        st.markdown("â‘ åœ¨å¤é€‰æ¡†ä¸­é€‰æ‹©éœ€è¦è¿›è¡Œä¼˜åŒ–çš„æ§åˆ¶å˜é‡ã€‚")
        st.markdown("â‘¡ç‚¹å‡»â€œè¾“å…¥ä¸Šä¸‹é™æŒ‰é’®â€ï¼Œè®¾ç½®å„æ§åˆ¶å˜é‡çš„ä¸‹é™ä¸ä¸Šé™ã€‚æ§åˆ¶å˜é‡çš„å–å€¼éœ€ç¬¦åˆå®é™…æƒ…å†µã€‚")
        st.markdown("â‘¢ç‚¹å‡»â€œå¼€å§‹â€æŒ‰é’®ï¼Œå¼€å§‹è¿›è¡Œæ¨¡å‹é¢„æµ‹æ§åˆ¶ã€‚")
        st.markdown("4. ç¼“å­˜æ¸…ç†")
        st.markdown("è‹¥éœ€è¦æ¸…ç†ç¼“å­˜ï¼Œè¯·ç‚¹å‡»ç½‘é¡µæœ€ä¸‹æ–¹çš„â€œæ¸…ç†ç¼“å­˜â€æŒ‰é’®ã€‚")
        st.markdown("5. æ³¨æ„äº‹é¡¹")
        st.markdown("åœ¨è¿›è¡Œæ¨¡å‹è®­ç»ƒã€ç‰¹å¾æŠ½æç­‰éœ€è¦è¾ƒé•¿æ—¶é—´çš„æ“ä½œæ—¶ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼Œé¿å…é¢‘ç¹æ“ä½œå¯¼è‡´ç³»ç»Ÿä¸ç¨³å®š")
        st.markdown("æœ¬ç³»ç»Ÿä»…é€‚ç”¨äºç¬¦åˆè§„å®šæ ¼å¼çš„è®­ç»ƒæ•°æ®ï¼Œä¸Šä¼ çš„æ•°æ®åº”ä¸¥æ ¼æŒ‰ç…§è¯´æ˜ä¹¦ä¸­è¦æ±‚çš„æ ¼å¼è¿›è¡Œæ•´ç†")
        st.markdown("6. ç‰ˆæƒè¯´æ˜")
        st.markdown("å­™å±•éµ¾ æå‹å…ƒ(yyli@ecust.edu.cn) * åä¸œç†å·¥å¤§å­¦ç”Ÿç‰©å·¥ç¨‹å­¦é™¢ Copyright 2025")

st.header("1.æ–‡ä»¶è¯»å–")
# æ–‡ä»¶ä¸Šä¼ 
uploaded_file = st.file_uploader("é€‰æ‹©ä¸€ä¸ª Excel æ–‡ä»¶", type=["xlsx", "xls"],key="file_uploader_0")
# å¦‚æœç”¨æˆ·ä¸Šä¼ äº†æ–‡ä»¶
if uploaded_file is not None:
    #æ–‡ä»¶è¯»å–
    excel_file = pd.ExcelFile(uploaded_file, engine="openpyxl")
    xls = pd.ExcelFile(excel_file)
    df1 = pd.read_excel(xls)
    # æ–‡ä»¶é¢„è§ˆ
    # åˆ›å»ºæŒ‰é’®
    if st.button('æ–‡ä»¶é¢„è§ˆ'):
        st.session_state.a = 'a'
    # æ˜¾ç¤ºç»“æœ
    if 'a' in st.session_state:
        st.subheader('æ•°æ®é¢„è§ˆ')
        st.write(df1.head())

    mpc_lis = df1.columns#åŸå§‹ç‰¹å¾
    #æ“ä½œå‚æ•°
    options_mpc_0 = st.multiselect(
        label='è¯·é€‰æ‹©æ“ä½œå‚æ•°',
        options=mpc_lis,
        default=None,
        format_func=str,
    )

st.header("2.ç‰¹å¾æ‹“å±•")
options = st.multiselect(
        label='è¯·é€‰æ‹©æ‹“å±•ç‰¹å¾ç±»å‹',
        options=('å˜åŒ–ç‰¹å¾', 'å˜åŒ–ç‡ç‰¹å¾', 'æ—¶åºç‰¹å¾', 'å¤šé¡¹å¼ç‰¹å¾', 'ç´¯ç§¯ç‰¹å¾', 'è½¬åŒ–ç‡ç‰¹å¾', 'ç”Ÿç‰©å­¦ç‰¹å¾'),
        default=None,
        format_func=str,
        help='è¯·é€‰æ‹©æ‹“å±•ç‰¹å¾ç±»å‹'
    )
if st.button('å¼€å§‹æ‹“å±•'):
    st.session_state.b = 'b'

if 'b' in st.session_state:
    # æ·»åŠ å‘é…µæ—¶é—´
    n1 = xd0()
    if 'å˜åŒ–ç‰¹å¾' in options :
        xd1()
    if 'å˜åŒ–ç‡ç‰¹å¾' in options :
        xd2()
    if 'æ—¶åºç‰¹å¾' in options :
        xd3()
    if 'å¤šé¡¹å¼ç‰¹å¾' in options :
        xd4()
    if 'ç´¯ç§¯ç‰¹å¾' in options :
        xd5()
    if 'è½¬åŒ–ç‡ç‰¹å¾' in options :
        xd6()
    if 'ç”Ÿç‰©å­¦ç‰¹å¾' in options :
        xd7()
    xd8()
    xd9()

    st.session_state.processed_excel = file_out.getvalue()
    st.download_button(
        label="ğŸ“¥ ç«‹å³ä¸‹è½½ä¿®æ”¹åçš„ Excel æ–‡ä»¶",
        data=st.session_state.processed_excel,
        file_name="é¢„å¤„ç†åè®­ç»ƒæ•°æ®.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        key="download_button"
    )

st.header("3.ç‰¹å¾æŠ½æ")

uploaded_file_1 = st.file_uploader("é€‰æ‹©å¤„ç†å¥½çš„è®­ç»ƒæ•°æ®æ–‡ä»¶", type=["xlsx", "xls"],key="file_uploader_1")

if st.button('å¼€å§‹ç‰¹å¾æŠ½æ'):
    st.session_state.c = 'c'
if 'c' in st.session_state:
    #äº§ç‰©
    st.write('é¢„æµ‹äº§ç‰©ç‰¹å¾æŠ½æ:')
    aflist = fscore1_a(pre1)#è®¡ç®—f-scoreå€¼
    aEV = fscore_a(pre1, aflist)#ç‰¹å¾æŠ½æï¼šæœ€ä½³ç‰¹å¾æ•°
    acid_con = list(dict.fromkeys([item[0] for item in aflist][:aEV] + options_mpc_0))#æ“ä½œå‚æ•°ç»“åˆæŠ½æç‰¹å¾
    st.write('é€‰æ‹©ç‰¹å¾æ•°ï¼š', len(acid_con))
    st.write(acid_con)
    #åº•ç‰©
    st.write('é¢„æµ‹åº•ç‰©ç‰¹å¾æŠ½æï¼š')
    sflist = fscore1_s(pre2)#è®¡ç®—f-scoreå€¼
    sEV = fscore_s(pre2, sflist)#ç‰¹å¾æŠ½æï¼šæœ€ä½³ç‰¹å¾æ•°
    sur_con = list(dict.fromkeys([item[0] for item in sflist][:sEV] + options_mpc_0))#æ“ä½œå‚æ•°ç»“åˆæŠ½æç‰¹å¾
    st.write('é€‰æ‹©ç‰¹å¾æ•°ï¼š', len(sur_con))
    st.write(sur_con)

st.header("4.æ¨¡å‹è®­ç»ƒ")
if st.button('å¼€å§‹è®­ç»ƒäº§ç‰©é¢„æµ‹æ¨¡å‹'):
    st.session_state.d = 'd'
if 'd' in st.session_state:#äº§ç‰©é¢„æµ‹æ¨¡å‹
    svrmse_aa = 'æœªé¢„æµ‹'
    plssvrmse_aa = 'æœªé¢„æµ‹'
    svrm_aa, svrmse_aa,sacX,sacy = svrm_a(pre1, acid_con)#SVRæ¨¡å‹é¢„è®­ç»ƒä¸ä¼˜åŒ–
    plssvrm_aa, plssvrmse_aa,psacX,psacy,ps_aa = plssvrm_a(pre1, acid_con)#PLS-SVRæ¨¡å‹é¢„è®­ç»ƒä¸ä¼˜åŒ–
    svrmse_aa=round(svrmse_aa,4)
    plssvrmse_aa=round(plssvrmse_aa,4)

if st.button('å¼€å§‹è®­ç»ƒåº•ç‰©é¢„æµ‹æ¨¡å‹'):
    st.session_state.e = 'e'
if 'e' in st.session_state:#åº•ç‰©é¢„æµ‹æ¨¡å‹
    svrmse_ss = 'æœªé¢„æµ‹'
    plssvrmse_ss = 'æœªé¢„æµ‹'
    svrm_ss, svrmse_ss ,sscX,sscy= svrm_s(pre2, sur_con)#SVRæ¨¡å‹é¢„è®­ç»ƒä¸ä¼˜åŒ–
    plssvrm_ss, plssvrmse_ss ,psscX,psscy,ps_ss= plssvrm_s(pre2, sur_con)#PLS-SVRæ¨¡å‹é¢„è®­ç»ƒä¸ä¼˜åŒ–
    svrmse_ss = round(svrmse_ss, 4)
    plssvrmse_ss = round(plssvrmse_ss, 4)

st.header("5.é¢„æµ‹")
# æ–‡ä»¶ä¸Šä¼ 
uploaded_file1 = st.file_uploader("é€‰æ‹©ä¸€ä¸ª Excel æ–‡ä»¶", type=["xlsx", "xls"],key="file_uploader_2")
# å¦‚æœç”¨æˆ·ä¸Šä¼ äº†æ–‡ä»¶
if uploaded_file1 is not None:
    # æ–‡ä»¶è¯»å–
    excel_file1 = pd.ExcelFile(uploaded_file1, engine="openpyxl")
    xls1 = pd.ExcelFile(excel_file1)
    df11 = pd.read_excel(xls1)
    perld = st.number_input("è¾“å…¥å‘é…µå‘¨æœŸ")
    # æ–‡ä»¶é¢„è§ˆ
    # åˆ›å»ºæŒ‰é’®
    if st.button('è¾“å…¥æ•°æ®é¢„å¤„ç†'):
        st.session_state.f = 'f'
    # æ˜¾ç¤ºç»“æœ
    if 'f' in st.session_state:
        m1 = xd00()#å‘é…µæ—¶é—´
        if 'å˜åŒ–ç‰¹å¾' in options :
            xd11()
        if 'å˜åŒ–ç‡ç‰¹å¾' in options :
            xd22()
        if 'æ—¶åºç‰¹å¾' in options :
            xd33()
        if 'å¤šé¡¹å¼ç‰¹å¾' in options :
            xd44()
        if 'ç´¯ç§¯ç‰¹å¾' in options :
            xd55()
        if 'è½¬åŒ–ç‡ç‰¹å¾' in options :
            xd66()
        if 'ç”Ÿç‰©å­¦ç‰¹å¾' in options :
            xd77()
        df22,prdata=xd88()

if st.button('å¼€å§‹é¢„æµ‹äº§ç‰©'):
    st.session_state.g = 'g'
if 'g' in st.session_state:
    #é€‰æ‹©æ¨¡å‹
    model = st.radio(
            label='è¯·é€‰æ‹©äº§ç‰©é¢„æµ‹æ¨¡å‹',
            options=(f'SVR   MSE:{svrmse_aa}', f'PLS-SVR   MSE:{plssvrmse_aa}'),
            index=1,
            format_func=str,
            help='æ¨èä½¿ç”¨MSEè¾ƒå°çš„æ¨¡å‹'
        )
    if model == f'SVR   MSE:{svrmse_aa}':#é€‰æ‹©SVRæ¨¡å‹
        features = acid_con
        X = df22[features].to_numpy()
        predata1 = sacX.transform(X)#å½’ä¸€åŒ–
        y_preddata1_a = svrm_aa.predict(predata1[-1].reshape(1,-1))#é¢„æµ‹
        data_original = sacy.inverse_transform(y_preddata1_a.reshape(1,-1))#å¤åŸæ•°æ®
        st.write(f'åº•ç‰©æ¶ˆè€—é€Ÿç‡ä¸º{(data_original[0]-prdata.iloc[1])/prdata.iloc[m1-1]}')
        st.write(f'{perld}å{df22.columns[2]}é¢„è®¡æµ“åº¦ä¸º{data_original[0]}')

    elif model ==f'PLS-SVR   MSE:{plssvrmse_aa}':#é€‰æ‹©PLS-SVRæ¨¡å‹
        features = acid_con
        X = df22[features].to_numpy()
        predata1 = psacX.transform(X)#å½’ä¸€åŒ–
        predata1 = ps_aa(predata1[-1].reshape(1,-1))#plsé™ç»´
        y_preddata1_a = plssvrm_aa.predict(predata1)#é¢„æµ‹
        data_original = psacy.inverse_transform(y_preddata1_a.reshape(1,-1))#å¤åŸæ•°æ®
        st.write(f'åº•ç‰©æ¶ˆè€—é€Ÿç‡ä¸º{(data_original[0]-prdata.iloc[1])/prdata.iloc[m1-1]}')
        st.write(f'{perld}å{df22.columns[2]}é¢„è®¡æµ“åº¦ä¸º{data_original[0]}')

if st.button('å¼€å§‹é¢„æµ‹åº•ç‰©'):
    st.session_state.h = 'h'
if 'h' in st.session_state:
    #é€‰æ‹©æ¨¡å‹
    model = st.radio(
            label='è¯·é€‰æ‹©åº•ç‰©é¢„æµ‹æ¨¡å‹',
            options=(f'SVR   MSE:{svrmse_ss}', f'PLS-SVR   MSE:{plssvrmse_ss}'),
            index=1,
            format_func=str,
            help='æ¨èä½¿ç”¨MSEè¾ƒå°çš„æ¨¡å‹'
        )
    if model == f'SVR   MSE:{svrmse_ss}':#é€‰æ‹©SVRæ¨¡å‹
        features = sur_con
        X = df22[features].to_numpy()
        predata2 = sscX.transform(X)#å½’ä¸€åŒ–
        y_preddata2_s = svrm_ss.predict(predata2[-1].reshape(1,-1))#é¢„æµ‹
        data_original_s = sscy.inverse_transform(y_preddata2_s.reshape(1,-1))#å¤åŸæ•°æ®
        st.write(f'åº•ç‰©æ¶ˆè€—é€Ÿç‡ä¸º{(data_original_s[0]-prdata.iloc[1])/prdata.iloc[m1-1]}')
        st.write(f'{perld}å{df22.columns[1]}é¢„è®¡æµ“åº¦ä¸º{data_original_s[0]}')

    elif model ==f'PLS-SVR   MSE:{plssvrmse_ss}':#é€‰æ‹©PLS-SVRæ¨¡å‹
        features = sur_con
        X = df22[features].to_numpy()
        predata2 = psscX.transform(X)#å½’ä¸€åŒ–
        predata2 = ps_ss(predata2[-1].reshape(1,-1))#é¢„æµ‹
        y_preddata2_s = plssvrm_ss.predict(predata2)#plsé™ç»´
        data_original_s = psscy.inverse_transform(y_preddata2_s.reshape(1,-1))#é¢„æµ‹
        st.write(f'åº•ç‰©æ¶ˆè€—é€Ÿç‡ä¸º{(data_original_s[0]-prdata.iloc[1])/prdata.iloc[m1-1]}')#å¤åŸæ•°æ®
        st.write(f'{perld}å{df22.columns[1]}é¢„è®¡æµ“åº¦ä¸º{data_original_s[0]}')

st.header("6.æ¨¡å‹é¢„æµ‹æ§åˆ¶")
#éœ€è¦ä¼˜åŒ–çš„æ“ä½œå‚æ•°
options_mpc = st.multiselect(
    label='è¯·é€‰æ‹©éœ€è¦ä¼˜åŒ–çš„æ“ä½œå‚æ•°',
    options=options_mpc_0,
    default=None,
    format_func=str,
)

if st.button('è¾“å…¥ä¸Šä¸‹é™'):
    st.session_state.i = 'i'
if 'i' in st.session_state:
    # çº¦æŸä¸è¾¹ç•Œ
    bounds = []
    # è¾“å…¥ä¸Šä¸‹é™
    for i in range(len(options_mpc)):
        st.write(f'è¯·è¾“å…¥{options_mpc[i]}ä¸Šä¸‹é™')
        input_value_min = st.number_input("è¯·è¾“å…¥ä¸‹é™", key=f"input_min_{i}")
        input_value_max = st.number_input("è¯·è¾“å…¥ä¸Šé™", key=f"input_max_{i}")
        bounds.append((input_value_min, input_value_max))

if st.button('å¼€å§‹'):
    st.session_state.j = 'j'
if 'j' in st.session_state:
    features = acid_con
    mpc_x = df22.iloc[-1][features]
    state_params = mpc_x.to_numpy()#çŠ¶æ€
    initial_control_params = mpc_x[options_mpc].to_numpy()#åˆå§‹æ“ä½œå‚æ•°
    indices = [acid_con.index(x) for x in options_mpc]#è·å¾—æ“ä½œå‚æ•°ç´¢å¼•
    def objective(control_params):
        # å°†æ”¹å˜çš„æ“ä½œå‚æ•°ä¸æŠ½æç‰¹å¾ç»„åˆ
        for i in indices:
            state_params[i] = control_params[indices.index(i)]
        input_features = sacX.transform(state_params.reshape(1, -1))#å½’ä¸€åŒ–
        # ä½¿ç”¨SVRæ¨¡å‹è¿›è¡Œé¢„æµ‹
        pre_mpc = svrm_aa.predict(input_features)#é¢„æµ‹
        prediction = sacy.inverse_transform(pre_mpc.reshape(1, 1))#å¤åŸ
        # ç›®æ ‡æ˜¯æœ€å¤§åŒ–é¢„æµ‹å€¼ï¼Œå› æ­¤è¿”å›è´Ÿå€¼ï¼ˆminimizeï¼‰
        return -prediction[0]

    # è°ƒç”¨ä¼˜åŒ–å‡½æ•°
    result = minimize(objective, initial_control_params, bounds=bounds, method="Nelder-Mead",options={'maxiter': 1000, 'disp': True})#Nelder-Meadæ–¹æ³•é€‚ç”¨äºä¸å¹³æ»‘å‡½æ•°ä¼˜åŒ–
    # è¾“å‡ºç»“æœ
    optimal_control_params = result.x
    max_prediction = -result.fun  # å› ä¸ºè¿”å›çš„æ˜¯è´Ÿå€¼ï¼Œåè½¬å›æ¥

    for i in range(len(options_mpc)):
        st.write(f"{options_mpc[i]}æœ€ä¼˜æ§åˆ¶å‚æ•°: {optimal_control_params[i]}")
    st.write(f"æœ€å¤§é¢„æµ‹å€¼: {max_prediction}")

# æ¸…é™¤ç¼“å­˜
st.header("7.ç¼“å­˜æ¸…ç†")
if st.button('æ¸…ç†ç¼“å­˜'):
    st.cache_data.clear()
    st.write("ç¼“å­˜å·²æ¸…ç†ï¼")

st.markdown("ç‰ˆæƒè¯´æ˜ï¼š å­™å±•éµ¾ æå‹å…ƒ(yyli@ecust.edu.cn) * åä¸œç†å·¥å¤§å­¦ç”Ÿç‰©å·¥ç¨‹å­¦é™¢ Copyright 2025")#ä½œè€… ç‰ˆæƒè¯´æ˜







